{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43a13d41-808c-4921-9188-0131a018a32e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/hilla.abramov@gmail.com/utils/stream_utils/extract_aws_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b81e5575-a44e-4687-b1dc-679ca21536c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class StreamProcessor:\n",
    "    def __init__(self, kinesis_stream_name, delta_table_name, json_schema, cleaning_function):\n",
    "        self.kinesis_stream_name = kinesis_stream_name\n",
    "        self.delta_table_name = delta_table_name\n",
    "        self.json_schema = json_schema\n",
    "        self.input_streaming_df = None\n",
    "        self.cleaned_streaming_df = None\n",
    "        self.cleaning_function = cleaning_function\n",
    "\n",
    "    def read_stream_from_kinesis_to_spark_df(self):\n",
    "        self.input_streaming_df = spark.readStream \\\n",
    "                                        .format('kinesis') \\\n",
    "                                        .option('streamName', self.kinesis_stream_name) \\\n",
    "                                        .option('initialPosition','earliest') \\\n",
    "                                        .option('region','us-east-1') \\\n",
    "                                        .option('awsAccessKey', ACCESS_KEY) \\\n",
    "                                        .option('awsSecretKey', SECRET_KEY) \\\n",
    "                                        .load() \\\n",
    "                                        .selectExpr(\"cast (data as STRING) jsonData\") \\\n",
    "                                        .select(from_json(\"jsonData\", self.json_schema).alias(self.kinesis_stream_name)) \\\n",
    "                                        .select(f\"{self.kinesis_stream_name}.*\")\n",
    "\n",
    "    def clean_stream_data(self):\n",
    "        self.cleaned_streaming_df = self.cleaning_function(self.input_streaming_df)\n",
    "    \n",
    "    def write_stream_to_delta_table(self):\n",
    "        \n",
    "        checkpoint_location = f\"/tmp/delta/{self.delta_table_name}/_checkpoints/\"\n",
    "        \n",
    "        # first remove checkpoint location if already exists\n",
    "        if checkpoint_location in dbutils.fs.ls(\"/tmp\"):\n",
    "            dbutils.fs.rm(checkpoint_location, True)\n",
    "\n",
    "        # write stream to delta table\n",
    "        self.cleaned_streaming_df.writeStream \\\n",
    "            .format(\"delta\") \\\n",
    "            .outputMode(\"append\") \\\n",
    "            .option(\"checkpointLocation\", checkpoint_location) \\\n",
    "            .table(self.delta_table_name)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self.read_stream_from_kinesis_to_spark_df()\n",
    "        self.clean_stream_data()\n",
    "        self.write_stream_to_delta_table()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "kinesis_stream_processor",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
