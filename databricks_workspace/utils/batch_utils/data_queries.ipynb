{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37d5a3af-54ad-4ef7-9d8f-95abca94161b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Find the most popular category people post to based on their country.\n",
    "\n",
    "Output written to /tmp/parquet/most_popular_category_per_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e641a6c-8d0e-4f3b-a79a-28df651b7679",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3814174645166129&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> sql_df1 = spark.sql(&#34;&#34;&#34;\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     WITH CTE AS (\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>         SELECT country<span class=\"ansi-blue-fg\">,</span> category<span class=\"ansi-blue-fg\">,</span> COUNT<span class=\"ansi-blue-fg\">(</span>category<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">as</span> category_count\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>         FROM hilla_pin\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>         INNER JOIN hilla_geo ON hilla_pin<span class=\"ansi-blue-fg\">.</span>ind <span class=\"ansi-blue-fg\">=</span> hilla_geo<span class=\"ansi-blue-fg\">.</span>ind\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: hilla_pin; line 4 pos 13;\n",
       "&#39;WithCTE\n",
       ":- &#39;CTERelationDef 143\n",
       ":  +- &#39;SubqueryAlias CTE\n",
       ":     +- &#39;Aggregate [&#39;country, &#39;category], [&#39;country, &#39;category, &#39;COUNT(&#39;category) AS category_count#2528963]\n",
       ":        +- &#39;Join Inner, (&#39;hilla_pin.ind = &#39;hilla_geo.ind)\n",
       ":           :- &#39;UnresolvedRelation [hilla_pin], [], false\n",
       ":           +- &#39;UnresolvedRelation [hilla_geo], [], false\n",
       ":- &#39;CTERelationDef 144\n",
       ":  +- &#39;SubqueryAlias max_counts\n",
       ":     +- &#39;Aggregate [&#39;country], [&#39;country, &#39;MAX(&#39;category_count) AS max_category_count_per_country#2528964]\n",
       ":        +- &#39;SubqueryAlias CTE\n",
       ":           +- &#39;CTERelationRef 143, false\n",
       "+- &#39;Sort [&#39;country ASC NULLS FIRST], true\n",
       "   +- &#39;Project [&#39;CTE.country, &#39;category, &#39;category_count]\n",
       "      +- &#39;Filter (&#39;category_count = &#39;max_category_count_per_country)\n",
       "         +- &#39;Join RightOuter, (&#39;CTE.country = &#39;max_counts.country)\n",
       "            :- &#39;SubqueryAlias CTE\n",
       "            :  +- &#39;CTERelationRef 143, false\n",
       "            +- &#39;SubqueryAlias max_counts\n",
       "               +- &#39;CTERelationRef 144, false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3814174645166129&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> sql_df1 = spark.sql(&#34;&#34;&#34;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     WITH CTE AS (\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>         SELECT country<span class=\"ansi-blue-fg\">,</span> category<span class=\"ansi-blue-fg\">,</span> COUNT<span class=\"ansi-blue-fg\">(</span>category<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">as</span> category_count\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>         FROM hilla_pin\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>         INNER JOIN hilla_geo ON hilla_pin<span class=\"ansi-blue-fg\">.</span>ind <span class=\"ansi-blue-fg\">=</span> hilla_geo<span class=\"ansi-blue-fg\">.</span>ind\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: hilla_pin; line 4 pos 13;\n&#39;WithCTE\n:- &#39;CTERelationDef 143\n:  +- &#39;SubqueryAlias CTE\n:     +- &#39;Aggregate [&#39;country, &#39;category], [&#39;country, &#39;category, &#39;COUNT(&#39;category) AS category_count#2528963]\n:        +- &#39;Join Inner, (&#39;hilla_pin.ind = &#39;hilla_geo.ind)\n:           :- &#39;UnresolvedRelation [hilla_pin], [], false\n:           +- &#39;UnresolvedRelation [hilla_geo], [], false\n:- &#39;CTERelationDef 144\n:  +- &#39;SubqueryAlias max_counts\n:     +- &#39;Aggregate [&#39;country], [&#39;country, &#39;MAX(&#39;category_count) AS max_category_count_per_country#2528964]\n:        +- &#39;SubqueryAlias CTE\n:           +- &#39;CTERelationRef 143, false\n+- &#39;Sort [&#39;country ASC NULLS FIRST], true\n   +- &#39;Project [&#39;CTE.country, &#39;category, &#39;category_count]\n      +- &#39;Filter (&#39;category_count = &#39;max_category_count_per_country)\n         +- &#39;Join RightOuter, (&#39;CTE.country = &#39;max_counts.country)\n            :- &#39;SubqueryAlias CTE\n            :  +- &#39;CTERelationRef 143, false\n            +- &#39;SubqueryAlias max_counts\n               +- &#39;CTERelationRef 144, false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: hilla_pin; line 4 pos 13;",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql_df1 = spark.sql(\"\"\"\n",
    "                WITH category_totals AS (\n",
    "                    SELECT\n",
    "                        country,\n",
    "                        category,\n",
    "                        COUNT(category) as category_count\n",
    "                    FROM\n",
    "                        hilla_pin\n",
    "                    INNER JOIN\n",
    "                        hilla_geo ON hilla_pin.ind = hilla_geo.ind\n",
    "                    GROUP BY\n",
    "                        country,\n",
    "                        category\n",
    "                ), category_ranks AS (\n",
    "                    SELECT\n",
    "                        country,\n",
    "                        category,\n",
    "                        category_count,\n",
    "                        RANK() OVER (\n",
    "                            PARTITION BY country\n",
    "                            ORDER BY category_count DESC\n",
    "                        ) as category_rank\n",
    "                    FROM category_totals\n",
    "                )\n",
    "                SELECT\n",
    "                    country,\n",
    "                    category,\n",
    "                    category_count\n",
    "                FROM\n",
    "                    category_ranks\n",
    "                WHERE\n",
    "                    category_rank = 1\n",
    "                ORDER BY country;\n",
    "                        \"\"\")\n",
    "\n",
    "sql_df1.write.mode(\"overwrite\").parquet(\"/tmp/parquet/most_popular_category_per_country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c447bac8-498a-4290-b272-8ec5857e28ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2a. Frequency of posts per category between 2018 and 2022, in order of popularity\n",
    "\n",
    "Output written to /tmp/parquet/frequency_of_posts_per_category_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33b626e0-dc49-441d-8cba-6a0fa8ad35c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df2a = spark.sql(\"\"\"\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    date_part('year', timestamp) as post_year,\n",
    "                    category,\n",
    "                    COUNT(category) as category_count\n",
    "                FROM\n",
    "                    hilla_pin\n",
    "                INNER JOIN\n",
    "                    hilla_geo ON hilla_pin.ind = hilla_geo.ind\n",
    "                GROUP BY\n",
    "                    post_year,\n",
    "                    category\n",
    "            )\n",
    "            SELECT\n",
    "                post_year,\n",
    "                category,\n",
    "                category_count\n",
    "            WHERE\n",
    "                post_year BETWEEN 2018 and 2022\n",
    "            ORDER BY\n",
    "                post_year,\n",
    "                category_count DESC;\n",
    "                        \"\"\")\n",
    "sql_df2a.write.mode(\"overwrite\").parquet(\"/tmp/parquet/frequency_of_posts_per_category_per_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cce025f0-ac80-4b4c-b985-9e1db6676f0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2b. Most popular post category per year\n",
    "\n",
    "Output written to /tmp/parquet/most_popular_category_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4acb5ac4-5f6f-47be-9151-6b065b22b396",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df2a.createOrReplaceTempView(\"frequency_of_posts_per_category_per_year\")\n",
    "\n",
    "sql_df2b = spark.sql(\"\"\"\n",
    "                    WITH\n",
    "                        frequency_of_posts_per_category_ranked AS (\n",
    "                    SELECT post_year,\n",
    "                            category,\n",
    "                            category_count,\n",
    "                            RANK() OVER (\n",
    "                            PARTITION BY post_year\n",
    "                            ORDER BY category_count DESC\n",
    "                            ) as category_rank\n",
    "                    FROM\n",
    "                        frequency_of_posts_per_category_per_year\n",
    "                    )\n",
    "                    SELECT\n",
    "                        post_year,\n",
    "                        category,\n",
    "                        category_count\n",
    "                    FROM\n",
    "                        frequency_of_posts_per_category_ranked\n",
    "                    WHERE\n",
    "                        category_rank = 1\n",
    "                    ORDER BY\n",
    "                        post_year;\n",
    "\"\"\")\n",
    "\n",
    "sql_df2b.write.mode(\"overwrite\").parquet(\"/tmp/parquet/most_popular_category_per_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8396c88b-504d-496b-a3ca-10d8195b4875",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3a. Find the user with most followers in each country\n",
    "\n",
    "Output written to /tmp/parquet/user_with_most_followers_per_country\n",
    "\n",
    "### 3b. Find the country with the user with most followers.\n",
    "\n",
    "Output written to /tmp/parquet/country_of_user_with_most_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72c5894e-900a-487f-8fdc-59c3bbe16613",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df3_1 = spark.sql(\"\"\"\n",
    "                WITH all_posters AS (\n",
    "                    SELECT\n",
    "                        country,\n",
    "                        poster_name,\n",
    "                        follower_count\n",
    "                    FROM\n",
    "                        hilla_pin\n",
    "                    LEFT JOIN\n",
    "                        hilla_geo ON hilla_pin.ind = hilla_geo.ind\n",
    "                ), follower_counts_ranked AS (\n",
    "                    SELECT\n",
    "                        country,\n",
    "                        poster_name,\n",
    "                        follower_count,\n",
    "                        RANK() OVER (\n",
    "                            PARTITION BY COUNTRY\n",
    "                            ORDER BY follower_count DESC\n",
    "                        ) follower_count_ranking\n",
    "                    FROM all_posters\n",
    "                )\n",
    "                SELECT DISTINCT\n",
    "                    country,\n",
    "                    poster_name,\n",
    "                    follower_count\n",
    "                FROM\n",
    "                    follower_counts_ranked\n",
    "                WHERE\n",
    "                    follower_count_ranking = 1\n",
    "                ORDER BY\n",
    "                    country;\n",
    "                        \"\"\")\n",
    "\n",
    "sql_df3_1.write.mode(\"overwrite\").parquet(\"/tmp/parquet/user_with_most_followers_per_country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd105da6-ec5e-4e3c-9574-8c02bc553eba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df3_1.createOrReplaceTempView(\"hilla_sql_df3_1\")\n",
    "\n",
    "sql_df3_2 = spark.sql(\"\"\"\n",
    "                SELECT\n",
    "                    country,\n",
    "                    follower_count\n",
    "                FROM (\n",
    "                    SELECT\n",
    "                        country,\n",
    "                        follower_count,\n",
    "                        RANK() OVER (\n",
    "                            ORDER BY follower_count DESC\n",
    "                        ) follower_count_ranking\n",
    "                    FROM\n",
    "                        hilla_sql_df3_1\n",
    "                    )\n",
    "                WHERE follower_count_ranking = 1;\n",
    "                    \"\"\")\n",
    "sql_df3_2.write.mode(\"overwrite\").parquet(\"/tmp/parquet/country_of_user_with_most_followers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29e4d7f7-b3e4-483d-aed2-48eef2d272c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Find the most popular category people post to based on the following age groups:\n",
    "\n",
    "- 18-24\n",
    "- 25-35\n",
    "- 36-50\n",
    "- +50\n",
    "\n",
    "Output written to /tmp/parquet/most_popular_category_per_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe114642-a1aa-4a4f-a4e2-68b8b4b60bc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df4 = spark.sql(\"\"\"\n",
    "            WITH category_counts AS (\n",
    "                SELECT\n",
    "                    category,\n",
    "                    COUNT(category) as category_count,\n",
    "                    CASE\n",
    "                        WHEN AGE < 25 THEN '18-24'\n",
    "                        WHEN AGE < 36 THEN '25-35'\n",
    "                        WHEN AGE < 51 THEN '36-50'\n",
    "                        ELSE '>50'\n",
    "                    END AS age_group\n",
    "                FROM\n",
    "                    hilla_pin\n",
    "                LEFT JOIN\n",
    "                    hilla_user ON hilla_pin.ind = hilla_user.ind\n",
    "                GROUP BY\n",
    "                    age_group,\n",
    "                    category\n",
    "            ), category_count_rankings AS (\n",
    "                SELECT\n",
    "                    age_group,\n",
    "                    category,\n",
    "                    category_count,\n",
    "                    RANK() OVER (\n",
    "                        PARTITION BY age_group\n",
    "                        ORDER BY category_count DESC\n",
    "                    ) category_count_ranking\n",
    "                FROM\n",
    "                    category_counts\n",
    "            )\n",
    "            SELECT\n",
    "                age_group,\n",
    "                category,\n",
    "                category_count\n",
    "            FROM\n",
    "                category_count_rankings\n",
    "            WHERE\n",
    "                category_count_ranking = 1;\n",
    "                    \"\"\")\n",
    "\n",
    "sql_df4.write.mode(\"overwrite\").parquet(\"/tmp/parquet/most_popular_category_per_age_group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8484e742-351c-4e05-ba6f-e83ac6e11186",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Find the median follower count for users in the following age groups:\n",
    "\n",
    "- 18-24\n",
    "- 25-35\n",
    "- 36-50\n",
    "- +50\n",
    "\n",
    "Output written to /tmp/parquet/median_follower_count_per_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a29097a3-d31a-4326-a8d4-ee6cbc4d6da8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df5 = spark.sql(\"\"\"\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN AGE < 25 THEN '18-24'\n",
    "                    WHEN AGE < 36 THEN '25-35'\n",
    "                    WHEN AGE < 51 THEN '36-50'\n",
    "                    ELSE '>50'\n",
    "                END AS age_group,\n",
    "                percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "            FROM\n",
    "                hilla_pin\n",
    "            LEFT JOIN\n",
    "                hilla_user ON hilla_pin.ind = hilla_user.ind\n",
    "            GROUP BY\n",
    "                age_group\n",
    "            ORDER BY\n",
    "                age_group;\n",
    "            \"\"\")\n",
    "\n",
    "sql_df5.write.mode(\"overwrite\").parquet(\"/tmp/parquet/median_follower_count_per_age_group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8e08fca-2cf7-4085-a874-904043ac14b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Find how many users have joined between 2015 and 2020.\n",
    "\n",
    "Ouput written to /tmp/parquet/new_users_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37c8613c-3724-48f8-9a89-81a80d045be3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df6 = spark.sql(\"\"\"\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    date_part('year', date_joined) as joining_year,\n",
    "                    COUNT(ind) as number_users_joined\n",
    "                FROM (\n",
    "                        SELECT DISTINCT *\n",
    "                        FROM hilla_user\n",
    "                )\n",
    "                GROUP BY\n",
    "                    joining_year\n",
    "                )\n",
    "            SELECT\n",
    "                joining_year,\n",
    "                number_users_joined\n",
    "            WHERE\n",
    "                joining_year BETWEEN 2015 and 2022\n",
    "            ORDER BY\n",
    "                joining_year;\n",
    "                        \"\"\")\n",
    "\n",
    "sql_df6.write.mode(\"overwrite\").parquet(\"/tmp/parquet/new_users_per_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b2a5514-2232-4bbc-be67-512926defbf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7. Find the median follower count of posts by users who joined between 2015 and 2020, based on joining year\n",
    "\n",
    "Output written to /tmp/parquet/median_follower_count_per_joining_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b35e36f-9932-4c2d-9bce-5477c38b757f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df7 = spark.sql(\"\"\"\n",
    "        FROM (\n",
    "            SELECT\n",
    "                date_part('year', date_joined) as joining_year,\n",
    "                follower_count\n",
    "            FROM\n",
    "                hilla_user\n",
    "            LEFT JOIN\n",
    "                hilla_pin ON hilla_user.ind = hilla_pin.ind\n",
    "            )\n",
    "        SELECT\n",
    "            joining_year,\n",
    "            percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "        WHERE\n",
    "            joining_year BETWEEN 2015 AND 2020\n",
    "        GROUP BY\n",
    "            joining_year\n",
    "        ORDER BY\n",
    "            joining_year;\n",
    "                \"\"\")\n",
    "\n",
    "sql_df7.write.mode(\"overwrite\").parquet(\"/tmp/parquet/median_follower_count_per_joining_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b28ab74a-dbe4-4b8f-9a24-131733d47152",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 8. Find the median follower count of posts by users that have joined between 2015 and 2020, based on their joining year and the age group they are part of\n",
    "\n",
    "Output written to /tmp/parquet/median_follower_count_per_joining_year_and_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b08656df-8bb2-4c9c-8db9-15d6286167fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df8 = spark.sql(\"\"\"\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN AGE < 25 THEN '18-24'\n",
    "                    WHEN AGE < 36 THEN '25-35'\n",
    "                    WHEN AGE < 51 THEN '36-50'\n",
    "                    ELSE '>50'\n",
    "                END AS age_group,\n",
    "                date_part('year', date_joined) as joining_year,\n",
    "                percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "            FROM\n",
    "                hilla_pin\n",
    "            RIGHT JOIN\n",
    "                hilla_user ON hilla_pin.ind = hilla_user.ind\n",
    "            GROUP BY\n",
    "                age_group,\n",
    "                joining_year\n",
    "            ORDER BY\n",
    "                joining_year,\n",
    "                age_group;\n",
    "                    \"\"\")\n",
    "\n",
    "sql_df8.write.mode(\"overwrite\").parquet(\"/tmp/parquet/median_follower_count_per_joining_year_and_age_group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbc2d7f9-5790-4731-a51f-d32a6f5411ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 9. Find the median follower count of posts made by users between 2015 and 2020, based on posting year and user age group\n",
    "\n",
    "Output written to /tmp/parquet/median_follower_count_per_post_year_and_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b71a80-b42a-4025-b7a7-cdb5de8c6b35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sql_df9 = spark.sql(\"\"\"\n",
    "            SELECT\n",
    "                CASE\n",
    "                    WHEN AGE < 25 THEN '18-24'\n",
    "                    WHEN AGE < 36 THEN '25-35'\n",
    "                    WHEN AGE < 51 THEN '36-50'\n",
    "                    ELSE '>50'\n",
    "                END AS age_group,\n",
    "                date_part('year', timestamp) as post_year,\n",
    "                percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "            FROM\n",
    "                hilla_pin\n",
    "            JOIN\n",
    "                hilla_geo ON hilla_pin.ind = hilla_geo.ind\n",
    "            JOIN\n",
    "                hilla_user ON hilla_pin.ind = hilla_user.ind\n",
    "            WHERE\n",
    "                date_part('year', timestamp) BETWEEN 2015 AND 2020\n",
    "            GROUP BY\n",
    "                age_group,\n",
    "                post_year\n",
    "            ORDER BY\n",
    "                post_year,\n",
    "                age_group;\n",
    "                    \"\"\")\n",
    "\n",
    "sql_df9.write.mode(\"overwrite\").parquet(\"/tmp/parquet/median_follower_count_per_post_year_and_age_group\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_queries",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
