{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e797278-0785-4f96-b067-9d5743bf3171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This script contains the dataframe cleaning methods defined for each dataset (to be used in both the batch and the stream processing pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bdb10bb-9918-453f-9d88-311b3f59e1cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import re\n",
    "\n",
    "from pyspark.sql.functions import col, concat_ws, to_timestamp, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8a2daa9-e662-46c0-9a97-a71b53af14db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the method for cleaning the Pinterest posts dataframe\n",
    "\n",
    "def convert_follower_count_letters_to_digits(str):\n",
    "    if str is not None:\n",
    "        str = re.sub(r'M', '000000', str)\n",
    "        str = re.sub(r'k', '000', str)\n",
    "        return str\n",
    "    \n",
    "follower_count_UDF = udf(lambda x:convert_follower_count_letters_to_digits(x))\n",
    "\n",
    "def strip_down_to_save_location_filepath(str):\n",
    "    if str is not None:\n",
    "        str = re.sub(r'Local save in ', '', str)\n",
    "        return str\n",
    "    \n",
    "save_location_UDF = udf(lambda x:strip_down_to_save_location_filepath(x))\n",
    "\n",
    "def clean_pin_df(df_pin):\n",
    "\n",
    "    # remove duplicate rows\n",
    "    df_pin = df_pin.distinct()\n",
    "\n",
    "    # replace entries with no data or no useful data with None\n",
    "    df_pin = df_pin.na.replace({\"User Info Error\": None}, 'follower_count')\n",
    "    df_pin = df_pin.na.replace({\"No description available\": None,\n",
    "                                \"No description available Story format\": None}, 'description')\n",
    "    df_pin = df_pin.na.replace({\"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\": None}, 'tag_list')\n",
    "    df_pin = df_pin.na.replace({\"No Title Data Available\": None}, 'title')\n",
    "    df_pin = df_pin.na.replace({\"Image src error.\": None}, 'image_src')\n",
    "\n",
    "    # convert all follower_count entries to numeric values\n",
    "    df_pin = df_pin.withColumn(\"follower_count\", follower_count_UDF(col(\"follower_count\")).cast(IntegerType()))\n",
    "\n",
    "    # clean save_location column to include just filepath\n",
    "    df_pin = df_pin.withColumn(\"save_location\", save_location_UDF(col(\"save_location\")))\n",
    "\n",
    "    # rename index column to ind\n",
    "    df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "    # reorder the columns (NB this drops the downloaded column)\n",
    "    df_pin = df_pin.select([\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\"])\n",
    "\n",
    "    # TODO: also turn tag list strings into array values?\n",
    "\n",
    "    return df_pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d75dd74-b816-4aa9-98d2-82fe6454160f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the method for cleaning the geolocation dataframe\n",
    "\n",
    "def clean_geo_df(df_geo):\n",
    "    \n",
    "    df_geo = df_geo.withColumn(\"coordinates\", array(col(\"latitude\"), col(\"longitude\")))\n",
    "    df_geo = df_geo.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy:MM:dd HH:mm:ss\"))\n",
    "\n",
    "    # reorder the columns and drop the longitude and latitude columns\n",
    "    df_geo = df_geo.select([\"ind\", \"country\", \"coordinates\", \"timestamp\"])\n",
    "\n",
    "    return df_geo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faf5d9cb-e888-447a-9068-8330eeebe574",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the method for cleaning the users dataframe\n",
    "\n",
    "def clean_user_df(df_user):\n",
    "\n",
    "    # create a new column user_name that concatenates the information found in the first_name and last_name columns\n",
    "    df_user = df_user.withColumn(\"user_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\")))\n",
    "\n",
    "    # convert date_joined column from string to timestamp data type\n",
    "    df_user = df_user.withColumn(\"date_joined\", to_timestamp(col(\"date_joined\"), \"yyyy:MM:dd HH:mm:ss\"))\n",
    "\n",
    "    # reorder the columns and drop the longitude and latitude columns, dropping first_name and last_name columns\n",
    "    df_user = df_user.select([\"ind\", \"user_name\", \"age\", \"date_joined\"]) \n",
    "\n",
    "    return df_user"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_cleaning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
